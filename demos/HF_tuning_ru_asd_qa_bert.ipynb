{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPjIzaePHnmLS3h2c/rbmqq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vifirsanova/empi/blob/main/demos/HF_tuning_ru_asd_qa_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzIy7ho54J9O",
        "outputId": "21ae33cd-8bcb-4ecd-82bb-a691ebd49d46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 11 15:34:53 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "i9PkUwE1j6B8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "SUepEp1cj7uP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393,
          "referenced_widgets": [
            "60ea7230f6db4262b1ab66bbcd3ad9e9",
            "59259dabefdb43c9a37e38355314e92e",
            "ccaf7d49b1814044808856ea76248692",
            "9b6a1e455cb748b685743b9555d0fbf5",
            "e3b586cddb704683b04b48597b7fcbf6",
            "1690cdf6338f412fb285024d8d7a8e9c",
            "22a8712b987345939ade695eadca77fc",
            "50c7e3f8b62f4a70842ba81604545cc9",
            "87cd9bb2eebd46bfacefce2c67ee13c7",
            "11d93d6adb3e457da379fbe739743319",
            "11eda52ad197437e8ae3dbeadc29ef10",
            "134d3809097144f0bde485cc87183c1d",
            "48654418d7f3457fa145de6485fdda45",
            "2650c7b8c7bd48ea8a8a0d102a14cf63",
            "6ed4c724c9bb4e38a982581ab20cbdbe",
            "34395b0ad87147e08db894788b64a784",
            "881ed5f19755433f83caf870c8db8cd3",
            "bcc5a4f599124b24804cad8c48851290",
            "fc453411709e4d74b9696c083e7c0ac8",
            "9acb7783672d49e9bf2a663868994b01",
            "5389a3ab832046d88146fe55d9d048f7",
            "75c306515ba344c3ba71aec6b79ef032",
            "a90efa0c50ee46ee9ace049b34037a1c",
            "9f165c031c9747759479a116f01465a8",
            "3bec9b200eb849c88ce515dffa7b30d2",
            "f1bda71256f34aa8bb99f6bcaee1c84e",
            "4413b2ad3fc4483493ef41a4a4e91bd1",
            "08c6a9182c1d4d6d8e126a5016b87b96",
            "a59994ecf53642d4a2aa36ec736fe5ed",
            "70985982ec6f447daedcb8a2abc98353",
            "b58cd0fc51b5428d9cfd511eb92432d9",
            "e7f612b8403544e88a2e3ff00a30ec08",
            "36852643e779432794a2b787730ad412",
            "339488d148244ebcba7a64f49d562e26",
            "98bc64a0e6de4a6893342e69dc2f9816",
            "97a58ab504cf4a8b8e8b4ca12f031f28",
            "a3538f0d860a4712acc4e593aee1dc27",
            "27eca234e29048d6986c4370edf6f2d7",
            "c9b405efd7394132b7e82ac6ee1769f9",
            "56bc783bd6f74c3589243a69aea1672c",
            "56c11c8fa7a44f4d9bb7c344379cda34",
            "0a1cfa7af9e341febee0b923cb9c64a6",
            "f18b1dcc435449b099d7ef0e60447278",
            "72eabb450849431ca51a14cc18e011cf",
            "873bd24fd792414aa3b5387e2a843f5a",
            "d16844e57a78438fb1fdc02a7a450f69",
            "c8835910d7cc47e9a69d6888db00b50c",
            "4c12cec1c1544288bda2c16ac4b04452",
            "b639f02191f74e9aaf2dcf848285317f",
            "fa29a6c17ff943b691f89a9505ad33d7",
            "2914b06f987a4dc182834c9ecf676afc",
            "ef1c84fefbc94d1c9ba78d72924366b6",
            "db4daf6c997d422f93124f3e26c2740f",
            "1db13749e3bd4d6e8975d8977b925bcc",
            "6e791e5df09e4831ae5d7b804013e32d",
            "a907ba493c5745f796c2bbb70842ecd4",
            "f54f24ed838f4709b551730907c56ce0",
            "157ef187816b40d193573bcfd78fbc62",
            "c764f411963a40f9bad9b7b5809203b1",
            "eef0e9eb4e92486ba0407ee59bf3ca46",
            "2c3b2b8d576949118666cb16bdec0f50",
            "f559901ffe9f4e27a836df79b6c6c681",
            "25957292928545708bbbf34664935cde",
            "c77e409cd0a4418995e7bce9c81446a0",
            "24d5e34a5a1f494695d1fd0d76e589f3",
            "2333830ccdfb4707981b07bc3f6783f2",
            "17580585a91848c9b01c2ed9e866389a",
            "fa8ec4c000774c928f4ee367b6b973e2",
            "8514a84a8bfe4f1c9d74dce31000a449",
            "c1586a12baa848a5af7dfafd89a7a0e6",
            "b5ee60c8130d4577a465e3625830efc4",
            "4c18b9690ed4478b8ae5de307ba018d3",
            "6e31ee55e4924fcfa2e2312c281fc1f0",
            "6382f0d0d9674673a4bc85d203204e0b",
            "9ef3cfe435e6494aa8fa1608c0fdf760",
            "3bb2e29c3b054ba099435146e7b5ce29",
            "c00ec2ad9b974efab3602cdc9fb6a1f5",
            "0562511d90224e5f879e04a3541704e6",
            "577b9ce3febd4ae68dfcded3e2a00f3b",
            "f6187477dbed45a0b25905175e25f3b7",
            "2a455683f34a4bd5a248892df625880f",
            "7ab51d5a3bd045798c3d0c5b0a003144",
            "f34fea71dc2f4096b395c5a59738d665",
            "33d0f84eb6dc4001bada6fb0b1e500a5",
            "e412bd163cd04efb8ce02c74e7953b09",
            "97ace58c499e492490facb064612441e",
            "ac813d05304644ae86e2d24d1852922b",
            "448435aa147a4bbb872fac3271896be8",
            "ad576857601f4b0abe226c160f4652dd",
            "df237eefd9de475fb56adf9e9c8d2e75",
            "e8c00a08cc1045f1904f3b0415a42ad1",
            "2247320dac124eb0b205088361ad2dcc",
            "bac21828d71b4f93980be0cebcdabb41",
            "d4c51c4f983242ffa7e20772968d8bcf",
            "f2cd954925824425949fc2fd95885945",
            "6b8554a4ef7d47c2b3de919d38718814",
            "b97d33fb8694425894a24a99bf167b7e",
            "d17e3957aacb494484ce9e7cf7bf8198",
            "72e82f80bb8942348c4c2faa57618e16",
            "2f93e588300f43089ab50ce90c7996a1",
            "a6231517fc154e4985aa0ac8a9fbcca7",
            "0e79a096f01e452abe4906ea77f0315e",
            "7292efd43172450b95c671d22f44642a",
            "6bb605d5e3dc49bb8a7f1b077a78d062",
            "0823c12d90e84c5b9e00d85f4202d11c",
            "64e03b2367d04a87a8c6df1a987dc391",
            "9087584af447437b87b15f50612f63c4",
            "d11e61d19a9449908d1abb415d3b95b9",
            "3a59be65e828438eb0171a8b3836684d",
            "952afa952d1c44948fa3a0a389d2584a"
          ]
        },
        "id": "L2cGsjZIYoy4",
        "outputId": "53390c44-b11a-424e-95cb-dfdf56487531"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60ea7230f6db4262b1ab66bbcd3ad9e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "134d3809097144f0bde485cc87183c1d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a90efa0c50ee46ee9ace049b34037a1c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/450k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "339488d148244ebcba7a64f49d562e26",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "873bd24fd792414aa3b5387e2a843f5a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/2593 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a907ba493c5745f796c2bbb70842ecd4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/477 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17580585a91848c9b01c2ed9e866389a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0562511d90224e5f879e04a3541704e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/55.0k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad576857601f4b0abe226c160f4652dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f93e588300f43089ab50ce90c7996a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/261 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"missvector/asd-qa-train\")\n",
        "val_dataset = load_dataset(\"missvector/asd-qa-val\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "137zL3rhLCR8"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=384,\n",
        "        truncation=\"only_second\",\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    answers = examples[\"answers\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offset in enumerate(offset_mapping):\n",
        "        answer = answers[i]\n",
        "        start_char = answer[\"answer_start\"][0]\n",
        "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        context_start = idx\n",
        "        while sequence_ids[idx] == 1:\n",
        "            idx += 1\n",
        "        context_end = idx - 1\n",
        "\n",
        "        # If the answer is not fully inside the context, label it (0, 0)\n",
        "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = context_start\n",
        "            while idx <= context_end and offset[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            start_positions.append(idx - 1)\n",
        "\n",
        "            idx = context_end\n",
        "            while idx >= context_start and offset[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')"
      ],
      "metadata": {
        "id": "Q58WZAMOu0-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Igpo8xgKYhAy"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset, tokenized_dataset_val = train_dataset.map(preprocess_function, batched=True, remove_columns=dataset['train'].column_names), val_dataset.map(preprocess_function, batched=True, remove_columns=val_dataset['train'].column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VtZuHk6Wkq7",
        "outputId": "b7c2f844-ebef-44d6-8ce3-17c564db0b53"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XLMRobertaForQuestionAnswering were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"xlm-roberta-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7pn1MA6WI8C"
      },
      "outputs": [],
      "source": [
        "from transformers import default_data_collator\n",
        "data_collator = default_data_collator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhGCVny3WpV2"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    overwrite_output_dir=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUL9HaUJZ4vW"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[0]['train'],\n",
        "    eval_dataset=tokenized_dataset_val[0]['train'],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "KzO8v9ofbKxy",
        "outputId": "f5434563-79a6-4a98-e927-61d69266a730"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7780' max='7779' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7779/7779 34:18, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.505100</td>\n",
              "      <td>2.384290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.047000</td>\n",
              "      <td>2.019877</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='222' max='261' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [222/261 00:07 < 00:01, 30.11 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub('missvector/ru-asd-qa-bert')"
      ],
      "metadata": {
        "id": "jDmN66JDjzdH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}