{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Pf4417qvoQbD",
        "AO2hMuTldpdh",
        "jR6dVGhJd09L",
        "X6GHxAQDd5hM",
        "4zhqxuJ_wGw5",
        "05BW9spUS3RX",
        "vxNdzVq0YDNb"
      ],
      "mount_file_id": "1nxVfZnmUXga4VzAnCgz89B9aLbfgGv2N",
      "authorship_tag": "ABX9TyN+TkO2dxnMSqwq7TdBme9/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vifirsanova/empi/blob/main/demos/greetings_scenario.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Приветственный сценарий работы чат-бота Эмпик**\n",
        "\n",
        "*Эмпик - модель Conversational AI для инклюзивного образования. Первый запуск модели сопровождается приветственным сценарием, который вы можете опробовать в этом ноутбуке.*\n",
        "\n",
        "**Эмпик анализирует, распознает и сохраняет:**\n",
        "- имя пользователя\n",
        "  - распознается автоматически с помощью NER\n",
        "- настройки мобильного приложения EMPI AI\n",
        "  - распознаются автоматически с помощью рекурсивного алгоритма поиска по графу - [базе знаний EMPI](https://github.com/vifirsanova/empi/blob/main/demos/graph_crowdsoursing_ui.ipynb)\n",
        "- историю общения с пользователем\n",
        "  - модель ведет лог для интерпретации результатов работы чат-бота в исследовательских целях (Explainable AI)\n",
        "\n",
        "**Отказ от ответственности**\n",
        "\n",
        "Автор демо-версии ПО не несет ответственности за точность, полноту или качество предоставленной в выдачах ПО информации. Никакие претензии за материальный или нематериальный ущерб, вызванный использованием или неиспользованием предоставленной информации не принимаются.\n",
        "\n",
        "**Обратная связь**\n",
        "\n",
        "Автор демо-версии: [Виктория Фирсанова](https://vifirsanova.github.io/).\n",
        "Свою обратную связь вы можете отправить в Telegram @vifirsanova или на почту vifirsanova@gmail.com. Принимаются любые пожелания и предложения по разработке продукта."
      ],
      "metadata": {
        "id": "TITvJG1y2gXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Приветственный сценарий работы чат-бота Эмпик (демо-версия)**\n",
        "\n",
        "# загрузка библиотек\n",
        "!pip install spacy\n",
        "!spacy download ru_core_news_sm\n",
        "!pip install gensim\n",
        "\n",
        "# загрузка модулей\n",
        "import re\n",
        "from gensim.models import Word2Vec\n",
        "import spacy\n",
        "import json\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# граф знаний: открыть\n",
        "with open('/content/drive/MyDrive/updated.json', 'r') as f:\n",
        "  data = json.load(f)\n",
        "\n",
        "class NLProcessor:\n",
        "  \"\"\"\n",
        "  Модуль для предобработки текстов на естественном языке\n",
        "  \"\"\"\n",
        "  def __init__(self, model, nlp):\n",
        "    self.model = model # модель для эмбеддингов\n",
        "    self.nlp = nlp # модель для обработки текстов\n",
        "    self.named_entities = [] # для функции ner_extract\n",
        "\n",
        "  def tokenize(self, text):\n",
        "    return self.nlp(text)\n",
        "\n",
        "  def get_tokens(self, text, lower=True):\n",
        "    _text = self.tokenize(re.sub(r'[^\\w\\s-]', '', text))\n",
        "    return [token.text.lower() for token in _text] if lower == True else [token.text for token in _text]\n",
        "\n",
        "  def _synonyms(self, word, topn):\n",
        "    # n самых похожих по вектору слов\n",
        "    try:\n",
        "      synonyms = [elem[0] for elem in self.model.wv.most_similar(word)[:topn]]\n",
        "      return synonyms\n",
        "    except KeyError:\n",
        "      return word\n",
        "\n",
        "  def find_synonyms(self, text, topn=5):\n",
        "    syns = []\n",
        "    tokens = self.get_tokens(text)\n",
        "    for token in tokens:\n",
        "      for s in self._synonyms(token, topn=topn):\n",
        "        syns.append(s)\n",
        "    return syns\n",
        "\n",
        "  def ner_extract(self, text):\n",
        "    tokenized_text = self.tokenize(text)\n",
        "    return [(ent.text, ent.label_) for ent in tokenized_text.ents]\n",
        "\n",
        "class Search:\n",
        "  \"\"\"\n",
        "  Модуль для поиска по графу\n",
        "  \"\"\"\n",
        "  def __init__(self, nlprocessor):\n",
        "    self.path = []\n",
        "    self.matched = set()\n",
        "    self.nlprocessor = nlprocessor # класс NLProcessor\n",
        "\n",
        "  def graph_search(self, data, search):\n",
        "    for k in data:\n",
        "      if search in k.split():\n",
        "        self.path.append(data[k])\n",
        "        self.matched.add(search)\n",
        "      if isinstance(data[k], dict):\n",
        "        self.graph_search(data=data[k], search=search)\n",
        "        self.matched.add(search)\n",
        "      else:\n",
        "        if isinstance(data[k], str):\n",
        "          if search in data[k].split():\n",
        "            self.path.append(data[k])\n",
        "            self.matched.add(search)\n",
        "        else:\n",
        "          for elem in data[k]:\n",
        "            if search in elem.split():\n",
        "              self.path.append(data[k])\n",
        "              self.matched.add(search)\n",
        "\n",
        "  def searching(self, data, query, exact=False):\n",
        "    tokenized_query = self.nlprocessor.get_tokens(query)\n",
        "    synonyms = self.nlprocessor.find_synonyms(query)\n",
        "\n",
        "    for word in tokenized_query:\n",
        "      self.graph_search(data, word)\n",
        "\n",
        "    if exact == False:\n",
        "      for word in synonyms:\n",
        "        self.graph_search(data, word)\n",
        "    # возвращает путь к найденному объекту и все метчи из входных данных\n",
        "    return {'path': self.path, 'matches': list(self.matched)}\n",
        "\n",
        "class Greetings():\n",
        "  \"\"\"\n",
        "  Initial Generation: этот сценарий запускается при первом общении с пользователем\n",
        "  Сценарий 1: приветствие и распознавание специальных потребностей пользователя\n",
        "  Модель извлекает информацию из ответа пользователя, ищет совпадения в графовой базе знаний в ветке \"дизайн\",\n",
        "  передает команду в пользовательский интерфейс, чтобы включить специальные возможности\n",
        "  - настройка мобильного приложения EMPI AI\n",
        "  - создание первичного блока с пользовательской информацией\n",
        "  - имя пользователя\n",
        "  - специальные настройки\n",
        "  - история общения с диалоговой системой\n",
        "  \"\"\"\n",
        "  def __init__(self, nlprocessor, search):\n",
        "    self.nlprocessor = nlprocessor\n",
        "    self.search = search\n",
        "    self.log = '' # история общения с пользователем\n",
        "\n",
        "  def update_log(self):\n",
        "    self.log += self.response\n",
        "    self.log += self.prompt\n",
        "\n",
        "  def init_gen(self):\n",
        "    # извлекаем именованные сущности из ответа пользователя\n",
        "    self.response = \"ЭМПИК:\\nПривет! Как тебя зовут?\\n\"\n",
        "    self.prompt = input(self.response)\n",
        "    username_ner = nlprocessor.ner_extract(self.prompt)\n",
        "    # извлекаем первое имя собственное из найденных\n",
        "    global username\n",
        "    username = [x[0] for x in username_ner if x[1] == 'PER'][0]\n",
        "    self.update_log()\n",
        "\n",
        "    # запрашиваем информацию о нуждах пользователя\n",
        "    self.response = f\"\\nЭМПИК:\\nРасскажи мне о себе: что тебе нужно для комфортного общения со мной?\\\n",
        "    \\nНапример, озвучивание текста, крупный шрифт или упрощенный язык.\\n{username}: \"\n",
        "    self.prompt = input(self.response)\n",
        "    self.update_log()\n",
        "\n",
        "    # жадный поиск по графу (паттерн-матчинг)\n",
        "    global setting\n",
        "    setting = search.searching(data=data['empi']['дизайн'], query=self.prompt, exact=True)[\"path\"]\n",
        "    if len(setting) > 0:\n",
        "      self.response = f\"\\nЭМПИК:\\nОтлично! Я тебя понял. Включаю режим: <{setting[0]}>\"\n",
        "      print(self.response)\n",
        "    else:\n",
        "      self.response = '\\nЭМПИК:\\nОтлично! Давай общаться.'\n",
        "      print(self.response)\n",
        "    self.update_log()\n",
        "\n",
        "  def user_block(self):\n",
        "    block = dict()\n",
        "    block['username'] = username\n",
        "    block['init_log'] = greetings.log\n",
        "    block['setting'] = setting\n",
        "\n",
        "    with open(f\"{username}_block.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(block, f, ensure_ascii=False)\n",
        "\n",
        "# инициализация компонентов для первичной генерации:\n",
        "# процессор, поисковая система, привественный сценарий\n",
        "model = Word2Vec.load('/content/drive/MyDrive/word2vec_model(1).bin')\n",
        "nlp = spacy.load(\"ru_core_news_sm\")\n",
        "nlprocessor = NLProcessor(model, nlp)\n",
        "search = Search(nlprocessor)\n",
        "greetings = Greetings(nlprocessor, search)\n",
        "\n",
        "# тестирование\n",
        "clear_output()\n",
        "greetings.init_gen()\n",
        "greetings.user_block()"
      ],
      "metadata": {
        "id": "IX4bC-oMHpjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58d542c7-7f4c-4a6c-971a-41283f7d52d3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ЭМПИК:\n",
            "Привет! Как тебя зовут?\n",
            "Приветик! Меня зовут Аня.\n",
            "\n",
            "ЭМПИК:\n",
            "Расскажи мне о себе: что тебе нужно для комфортного общения со мной?    \n",
            "Например, озвучивание текста, крупный шрифт или упрощенный язык.\n",
            "Аня: Думаю, что мне понадобится распознавание речи.\n",
            "\n",
            "ЭМПИК:\n",
            "Отлично! Я тебя понял. Включаю режим: <распознавание речи>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Результат обработки приветственного сценария чат-бота:** блок с персональной пользовательской информацией\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "with open(f\"{username}_block.json\", 'r') as f:\n",
        "  block = json.load(f)\n",
        "\n",
        "pprint(block)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a71ccbb-b294-4990-ccfa-dfaf2d0da8be",
        "cellView": "form",
        "id": "oRxC6pwH4-QZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'init_log': 'ЭМПИК:\\n'\n",
            "             'Привет! Как тебя зовут?\\n'\n",
            "             'Приветик! Меня зовут Аня.\\n'\n",
            "             'ЭМПИК:\\n'\n",
            "             'Расскажи мне о себе: что тебе нужно для комфортного общения со '\n",
            "             'мной?    \\n'\n",
            "             'Например, озвучивание текста, крупный шрифт или упрощенный '\n",
            "             'язык.\\n'\n",
            "             'Аня: Думаю, что мне понадобится распознавание речи.\\n'\n",
            "             'ЭМПИК:\\n'\n",
            "             'Отлично! Я тебя понял. Включаю режим: <распознавание речи>Думаю, '\n",
            "             'что мне понадобится распознавание речи.',\n",
            " 'setting': ['распознавание речи',\n",
            "             'распознавание речи',\n",
            "             {'для кого': ['рас',\n",
            "                           'афазия',\n",
            "                           'нарушения процесса порождения речи'],\n",
            "              'принцип работы': 'технология автоматического воспроизведения '\n",
            "                                'текста, например, функция “прямая речь” в '\n",
            "                                'iphone',\n",
            "              'технология': 'text-to-speech'},\n",
            "             ['рас', 'афазия', 'нарушения процесса порождения речи']],\n",
            " 'username': 'Аня'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Персональный блок содержит имя пользователя `username`, настройки приложения EMPI AI `setting`, историю общения с пользователем `init log`. Настройки позволяют обеспечить **доступность EMPI AI**, например, включить режим надиктовывания и озвучивания текста на экране для людей с нарушениями зрения."
      ],
      "metadata": {
        "id": "PDKgzbl45Ku0"
      }
    }
  ]
}