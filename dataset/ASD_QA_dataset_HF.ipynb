{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMw0WYE233U6c6+qsNaAKRf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vifirsanova/empi/blob/main/dataset/ASD_QA_dataset_HF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook was created by [Victoria Firsanova](https://vifirsanova.github.io)\n",
        "\n",
        "The notebook describes the process of preparing [the ASD QA dataset](https://figshare.com/articles/dataset/Autism_Spectrum_Disorder_and_Asperger_Syndrome_Question_Answering_Dataset_1_0/13295831) for HuggingFace"
      ],
      "metadata": {
        "id": "MVXiASE7Ux5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "Cqzktu5Uc8Cm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "qEQ8Y8fschuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4QrkIoGTUecn"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "hXW23kQ2c-9d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First things first, I uploaded the dataset to Colab"
      ],
      "metadata": {
        "id": "HQs0lUZDc5cA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = Path('original.json')\n",
        "data = json.loads(path.read_text(encoding='utf-8'))\n",
        "\n",
        "data = data['data']"
      ],
      "metadata": {
        "id": "Y_lQXPXyc3IE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset stats"
      ],
      "metadata": {
        "id": "Msb4U9FqdC3R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's look at some stats"
      ],
      "metadata": {
        "id": "wu2GnXfoWD1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c_len_t = []\n",
        "c_len_w = []\n",
        "\n",
        "for i in range(len(data)):\n",
        "  for paragraph in data[i]['paragraphs']:\n",
        "    c_len_t.append(len(paragraph['context']))\n",
        "    c_len_w.append(len(paragraph['context'].split()))\n",
        "\n",
        "qa_stats = 0\n",
        "\n",
        "for i in range(len(data)):\n",
        "  for paragraph in data[i]['paragraphs']:\n",
        "    qa_stats += len(paragraph['qas'])\n",
        "\n",
        "\n",
        "fakes = 0\n",
        "ans_len_t = []\n",
        "q_len_t = []\n",
        "ans_len_w = []\n",
        "q_len_w = []\n",
        "\n",
        "for i in range(len(data)):\n",
        "  for paragraph in data[i]['paragraphs']:\n",
        "    for elem in paragraph['qas']:\n",
        "      q_len_t.append(len(elem['question']))\n",
        "      q_len_w.append(len(elem['question'].split()))\n",
        "      if elem['is_impossible'] == True:\n",
        "        fakes += 1\n",
        "      if len(elem['answers'][0]['text']) > 0:\n",
        "        ans_len_t.append(len(elem['answers'][0]['text']))\n",
        "        ans_len_w.append(len(elem['answers'][0]['text'].split()))\n",
        "\n",
        "print('The number of QA pairs', qa_stats)\n",
        "print('The number of irrelevant questions', fakes)\n",
        "print('The average question length', round(sum(q_len_t) / len(q_len_t)), 'symbols', round(sum(q_len_w) / len(q_len_w)), 'words')\n",
        "print('The average answer length', round(sum(ans_len_t) / len(ans_len_t)), 'symbols', round(sum(ans_len_w) / len(ans_len_w)), 'words')\n",
        "print('The average reading paragraph length', round(sum(c_len_t) / len(c_len_t)), 'symbols', round(sum(c_len_w) / len(c_len_w)), 'words')\n",
        "print('Max question length', max(q_len_t), 'symbols', max(q_len_w), 'words')\n",
        "print('Max answer length', max(ans_len_t), 'symbols', max(ans_len_w), 'words')\n",
        "print('Max reading paragraph length', max(c_len_t), 'symbols', max(c_len_w), 'words')\n",
        "print('Min question length', min(q_len_t), 'symbols', min(q_len_w), 'words')\n",
        "print('Min answer length', min(ans_len_t), 'symbols', min(ans_len_w), 'words')\n",
        "print('Min reading paragraph length', min(c_len_t), 'symbols', min(c_len_w), 'words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvSM_8ImWDMr",
        "outputId": "0a9e4364-75ce-4e11-8bf1-c60c76c90f31"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of QA pairs 4138\n",
            "The number of irrelevant questions 352\n",
            "The average question length 53 symbols 8 words\n",
            "The average answer length 141 symbols 20 words\n",
            "The average reading paragraph length 453 symbols 63 words\n",
            "Max question length 226 symbols 32 words\n",
            "Max answer length 555 symbols 85 words\n",
            "Max reading paragraph length 551 symbols 94 words\n",
            "Min question length 9 symbols 2 words\n",
            "Min answer length 5 symbols 1 words\n",
            "Min reading paragraph length 144 symbols 17 words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the data"
      ],
      "metadata": {
        "id": "SQxECsIIdF5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, temp = train_test_split(data, test_size=0.3, shuffle=True)\n",
        "val, test = train_test_split(temp, test_size=0.5, shuffle=True)"
      ],
      "metadata": {
        "id": "QMgenUYSWMC0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieve questions, answers and reading passages from the dataset -> form the dataframe"
      ],
      "metadata": {
        "id": "1juMOtJLdaUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qs = []\n",
        "ans = []\n",
        "pars = []\n",
        "\n",
        "def dict_from_data(sample):\n",
        "  for elem in sample:\n",
        "    for paragraph in elem['paragraphs']:\n",
        "      for element in paragraph['qas']:\n",
        "        qs.append (element['question'])\n",
        "        ans.append(element['answers'][0])\n",
        "        pars.append(paragraph['context'])\n",
        "\n",
        "  sample_dict = dict()\n",
        "\n",
        "  sample_dict['question'] = qs\n",
        "  sample_dict['answers'] = ans\n",
        "  sample_dict['paragraph'] = pars\n",
        "\n",
        "  return sample_dict\n",
        "\n",
        "train_dict, val_dict, test_dict = dict_from_data(train), dict_from_data(val), dict_from_data(test)"
      ],
      "metadata": {
        "id": "8_CdKlFRcxSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create HF Dataset"
      ],
      "metadata": {
        "id": "fCUax5STeUsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, val_dataset, test_dataset = Dataset.from_dict(train_dict), Dataset.from_dict(val_dict), Dataset.from_dict(test_dict)"
      ],
      "metadata": {
        "id": "izAA0oPLeIb9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDsX-H8Vedui",
        "outputId": "09818775-2651-43aa-b273-9bc37888b069"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'Как-то дети должны относится к особенным ровесникам?',\n",
              " 'answers': {'answer_end': 383,\n",
              "  'answer_start': 0,\n",
              "  'text': 'Братьев и сестёр надо учить правильно реагировать'},\n",
              " 'paragraph': 'Братьев и сестёр нужно учить правильно реагировать. Обычно это обращение к родителям за помощью в разрешении ситуации. Родителям нужно приложить все усилия, чтобы дать детям безопасное место для важных вещей и защитить от агрессивного поведения. Томас Пауэлл и Пегги Галлахер предлагают идеи по обучению базовым навыкам поведения братьев и сестёр. Сиблингам важно чувствовать, что с их братом или сестрой обращаются как можно более \"нормально\".\\xa0'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Push the data to HF"
      ],
      "metadata": {
        "id": "BTX1DY9LevWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.push_to_hub('missvector/asd-qa-train')\n",
        "val_dataset.push_to_hub('missvector/asd-qa-val')\n",
        "test_dataset.push_to_hub('missvector/asd-qa-test')"
      ],
      "metadata": {
        "id": "ZY_rhAExemlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the ASD QA dataset and its user friendly preview is available on HF\n",
        "\n",
        "1. [Train set](https://huggingface.co/datasets/missvector/asd-qa-train)\n",
        "2. [Validation set](https://huggingface.co/datasets/missvector/asd-qa-val)\n",
        "3. [Test set](https://huggingface.co/datasets/missvector/asd-qa-test)"
      ],
      "metadata": {
        "id": "J1OCy4Iae5AT"
      }
    }
  ]
}