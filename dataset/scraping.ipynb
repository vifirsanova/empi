{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMl2g5N7fpScpBu1G7Tl7Ru",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vifirsanova/empi/blob/main/dataset/scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "c1Offge4klq7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7VRPYOizkWgj"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate URLs"
      ],
      "metadata": {
        "id": "2fUlrBl5kp-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_urls(prefix):\n",
        "  \"\"\"\n",
        "  The function takes domain name (prefix) as input and outputs the list of urls\n",
        "  prefix: str()\n",
        "  \"\"\"\n",
        "\n",
        "  # list of urls\n",
        "\n",
        "  urls = []\n",
        "\n",
        "  for i in range(114, 606):\n",
        "    # add index to the prefix\n",
        "    url = prefix + str(i)\n",
        "    urls.append(url)\n",
        "\n",
        "  return urls"
      ],
      "metadata": {
        "id": "UaEFYvhfkbRx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urls = generate_urls('https://www.***.ru/node/')\n",
        "urls[:10]"
      ],
      "metadata": {
        "id": "BoSmj-Nnkt4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load files"
      ],
      "metadata": {
        "id": "Rh0HeSoBlIhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scraping(urls):\n",
        "  \"\"\"\n",
        "  Fuctions gets content from given pages\n",
        "\n",
        "  urls: list with urls (list)\n",
        "  \"\"\"\n",
        "  # data storage\n",
        "  data = []\n",
        "  f = open(\"data.txt\", \"a\")\n",
        "  # iterate over urls\n",
        "  for url in urls:\n",
        "    try:\n",
        "      r = requests.get(url)\n",
        "      # check the http response\n",
        "      status = r.status_code\n",
        "      # if successful returns 200\n",
        "      if status == 200:\n",
        "        # parse HTML with BeautifulSoup\n",
        "        soup = BeautifulSoup(r.content, 'html.parser')\n",
        "        temp = soup.get_text()\n",
        "        # save\n",
        "        f.write(temp)\n",
        "        data.append(temp)\n",
        "        # debugging string\n",
        "        print(f'The data is successfully loaded from {url}')\n",
        "      # if other response (e.g. 404)\n",
        "      else:\n",
        "        # debugging string\n",
        "        print(f'Bad response {r.status_code}')\n",
        "    # expection\n",
        "    except requests.exceptions.RequestException as e:\n",
        "      # error message\n",
        "      print(f'Error {e}')\n",
        "  f.close()\n",
        "  return data"
      ],
      "metadata": {
        "id": "UTsoDyJMk-B1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate data archive\n",
        "archive = scraping(urls)"
      ],
      "metadata": {
        "id": "p5paEI6KlMyv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}