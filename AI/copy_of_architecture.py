# -*- coding: utf-8 -*-
"""Copy of architecture.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FjVv7yASR5exU2ki0u2210q-ciafJLkS
"""

!pip install spacy
!spacy download ru_core_news_sm
!pip install gensim

import json
import re
from gensim.models import Word2Vec
import spacy
from pprint import pprint
from IPython.display import clear_output

class NLProcessor:
  def __init__(self, model, nlp):
    self.model = model # модель для эмбеддингов
    self.nlp = nlp # модель для обработки текстов
    self.named_entities = [] # для функции ner_extract

  def tokenize(self, text):
    return self.nlp(text)

  def get_tokens(self, text, lower=True):
    _text = self.tokenize(re.sub(r'[^\w\s-]', '', text))
    return [token.text.lower() for token in _text] if lower == True else [token.text for token in _text]

  def _synonyms(self, word, topn):
    # n самых похожих по вектору слов
    try:
      synonyms = [elem[0] for elem in self.model.wv.most_similar(word)[:topn]]
      return synonyms
    except KeyError:
      return word

  def find_synonyms(self, text, topn=5):
    syns = []
    tokens = self.get_tokens(text)
    for token in tokens:
      for s in self._synonyms(token, topn=topn):
        syns.append(s)
    return syns

  def ner_extract(self, text):
    tokenized_text = self.tokenize(text)
    return [(ent.text, ent.label_) for ent in tokenized_text.ents]

class Search:
  def __init__(self, nlprocessor):
    self.path = []
    self.matched = set()
    self.nlprocessor = nlprocessor # класс NLProcessor

  def graph_search(self, data, search):
    for k in data:
      if search in k.split():
        self.path.append(data[k])
        self.matched.add(search)
      if isinstance(data[k], dict):
        self.graph_search(data=data[k], search=search)
        self.matched.add(search)
      else:
        if isinstance(data[k], str):
          if search in data[k].split():
            self.path.append(data[k])
            self.matched.add(search)
        else:
          for elem in data[k]:
            if search in elem.split():
              self.path.append(data[k])
              self.matched.add(search)

  def searching(self, data, query, exact=False):
    tokenized_query = self.nlprocessor.get_tokens(query)
    synonyms = self.nlprocessor.find_synonyms(query)

    for word in tokenized_query:
      self.graph_search(data, word)

    if exact == False:
      for word in synonyms:
        self.graph_search(data, word)
    # возвращает путь к найденному объекту и все метчи из входных данных
    return {'path': self.path, 'matches': list(self.matched)}

class Greetings():
  """
  Initial Generation: этот сценарий запускается при первом общении с пользователем
  Сценарий 1: приветствие и распознавание специальных потребностей пользователя
  Модель извлекает информацию из ответа пользователя, ищет совпадения в графовой базе знаний в ветке "дизайн",
  передает команду в пользовательский интерфейс, чтобы включить специальные возможности
  """
  def __init__(self, nlprocessor, search):
    self.nlprocessor = nlprocessor
    self.search = search
    self.log = '' # история общения с пользователем

  def update_log(self):
    self.log += self.response
    self.log += self.prompt

  def init_gen(self):
    # извлекаем именованные сущности из ответа пользователя
    self.response = "ЭМПИК:\nПривет! Как тебя зовут?\n"
    self.prompt = input(self.response)
    username_ner = nlprocessor.ner_extract(self.prompt)
    # извлекаем первое имя собственное из найденных
    global username
    username = [x[0] for x in username_ner if x[1] == 'PER'][0]
    self.update_log()

    # запрашиваем информацию о нуждах пользователя
    self.response = f"\nЭМПИК:\nРасскажи мне о себе: что тебе нужно для комфортного общения со мной?\
    \nНапример, озвучивание текста, крупный шрифт или упрощенный язык.\n{username}: "
    self.prompt = input(self.response)
    self.update_log()

    # жадный поиск по графу (паттерн-матчинг)
    global setting
    setting = search.searching(data=data['empi']['дизайн'], query=self.prompt, exact=True)["path"]
    if len(setting) > 0:
      self.response = f"\nЭМПИК:\nОтлично! Я тебя понял. Включаю режим: <{setting[0]}>"
      print(self.response)
    else:
      self.response = '\nЭМПИК:\nОтлично! Давай общаться.'
      print(self.response)
    self.update_log()

def user_block():
  block = dict()
  block['username'] = username
  block['init_log'] = greetings.log
  block['setting'] = setting

  with open(f"{username}_block.json", "w", encoding="utf-8") as f:
      json.dump(block, f, ensure_ascii=False)

def cypher(prompt):
  """
  Block generation: работу этого сценария обеспечивает технология Blockchain
  Сценарий 2: поиск данных, уязвимых для хакеров
  Функция ищет указание на персональные данные пользователя с помощью поиска по базе знаний и шифрует их
  Функция возвращает исходный промпт с зашифрованными данными
  """
  # инициализация поискового модуля
  search = Search(nlprocessor)
  # поиск совпадение по графу
  private_data = search.searching(data=data['empi']['персональные данные'], query=prompt, exact=True)
  # шифруем персональные данные специальным токеном
  if len(private_data['matches']) > 0:
    return re.sub(rf'{private_data["matches"][0]}(.*)', f'<{private_data["path"][0]}>', prompt)
  else:
    return prompt

def retrieval(prompt):
  """
  Conditioning: этот сценарий обеспечивает работу алгоритма обусловленной генерации текста
  Сценарий 3: поиск информации для генерации полезного ответа
  Функция ищет по графу релевантную информацию и извлекает текст,
  который затем можно использовать для обусловленной генерации с помощью LLM
  """
  # инициализация поискового модуля
  search = Search(nlprocessor)
  # поиск совпадений по графу
  return list(set(search.searching(data=data['empi']['полезная информация'], query=prompt, exact=True)['path']))

def cta():
  """
  Hardware: этот сценарий предполагает работу с аппартным обеспечением
  Сценарий 4: обучающая или психотерапевтическая игра, призыв пользователя к действию
  Пример: навыки виртуального ассистента
  """
  print("\nЭМПИК:\nПодключи умные часы, чтобы запустить обучающую игру или трекер стресса")

def form_block(data, prompt):
  _prompt = cypher(prompt)
  data['log'] = _prompt
  data['related'] = retrieval(_prompt)
  # обновить
  with open(f"{username}_block.json", "w", encoding="utf-8") as f:
      json.dump(data, f, ensure_ascii=False)
  return data

# граф знаний: открыть
with open('/content/drive/MyDrive/updated.json', 'r') as f:
  data = json.load(f)

model = Word2Vec.load('/content/drive/MyDrive/word2vec_model(1).bin')
nlp = spacy.load("ru_core_news_sm")

nlprocessor = NLProcessor(model, nlp)
search = Search(nlprocessor)
greetings = Greetings(nlprocessor, search)

clear_output()

# тест

greetings.init_gen()
user_block()

with open(f"{username}_block.json", 'r') as f:
  current_block = json.load(f)

result_block = form_block(current_block, input(f'{username}: '))

cta()
print("\n\n***БЛОК СФОРМИРОВАН***\n\n")
pprint(result_block, depth=1)